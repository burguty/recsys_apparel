{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc3715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd2687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mouze\\AppData\\Local\\Temp\\ipykernel_22812\\2874807013.py:80: DeprecationWarning: the `streaming` parameter was deprecated in 1.25.0; use `engine` instead.\n",
      "  temp_agg.collect(streaming=True).write_parquet(output_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data\\train_data\\agg_chunk_0.parquet\n",
      "Processing chunk 2/200\n",
      "Saved data\\train_data\\agg_chunk_1.parquet\n",
      "Processing chunk 3/200\n",
      "Saved data\\train_data\\agg_chunk_2.parquet\n",
      "Processing chunk 4/200\n",
      "Saved data\\train_data\\agg_chunk_3.parquet\n",
      "Processing chunk 5/200\n",
      "Saved data\\train_data\\agg_chunk_4.parquet\n",
      "Processing chunk 6/200\n",
      "Saved data\\train_data\\agg_chunk_5.parquet\n",
      "Processing chunk 7/200\n",
      "Saved data\\train_data\\agg_chunk_6.parquet\n",
      "Processing chunk 8/200\n",
      "Saved data\\train_data\\agg_chunk_7.parquet\n",
      "Processing chunk 9/200\n",
      "Saved data\\train_data\\agg_chunk_8.parquet\n",
      "Processing chunk 10/200\n",
      "Saved data\\train_data\\agg_chunk_9.parquet\n",
      "Processing chunk 11/200\n",
      "Saved data\\train_data\\agg_chunk_10.parquet\n",
      "Processing chunk 12/200\n",
      "Saved data\\train_data\\agg_chunk_11.parquet\n",
      "Processing chunk 13/200\n",
      "Saved data\\train_data\\agg_chunk_12.parquet\n",
      "Processing chunk 14/200\n",
      "Saved data\\train_data\\agg_chunk_13.parquet\n",
      "Processing chunk 15/200\n",
      "Saved data\\train_data\\agg_chunk_14.parquet\n",
      "Processing chunk 16/200\n",
      "Saved data\\train_data\\agg_chunk_15.parquet\n",
      "Processing chunk 17/200\n",
      "Saved data\\train_data\\agg_chunk_16.parquet\n",
      "Processing chunk 18/200\n",
      "Saved data\\train_data\\agg_chunk_17.parquet\n",
      "Processing chunk 19/200\n",
      "Saved data\\train_data\\agg_chunk_18.parquet\n",
      "Processing chunk 20/200\n",
      "Saved data\\train_data\\agg_chunk_19.parquet\n",
      "Processing chunk 21/200\n",
      "Saved data\\train_data\\agg_chunk_20.parquet\n",
      "Processing chunk 22/200\n",
      "Saved data\\train_data\\agg_chunk_21.parquet\n",
      "Processing chunk 23/200\n",
      "Saved data\\train_data\\agg_chunk_22.parquet\n",
      "Processing chunk 24/200\n",
      "Saved data\\train_data\\agg_chunk_23.parquet\n",
      "Processing chunk 25/200\n",
      "Saved data\\train_data\\agg_chunk_24.parquet\n",
      "Processing chunk 26/200\n",
      "Saved data\\train_data\\agg_chunk_25.parquet\n",
      "Processing chunk 27/200\n",
      "Saved data\\train_data\\agg_chunk_26.parquet\n",
      "Processing chunk 28/200\n",
      "Saved data\\train_data\\agg_chunk_27.parquet\n",
      "Processing chunk 29/200\n",
      "Saved data\\train_data\\agg_chunk_28.parquet\n",
      "Processing chunk 30/200\n",
      "Saved data\\train_data\\agg_chunk_29.parquet\n",
      "Processing chunk 31/200\n",
      "Saved data\\train_data\\agg_chunk_30.parquet\n",
      "Processing chunk 32/200\n",
      "Saved data\\train_data\\agg_chunk_31.parquet\n",
      "Processing chunk 33/200\n",
      "Saved data\\train_data\\agg_chunk_32.parquet\n",
      "Processing chunk 34/200\n",
      "Saved data\\train_data\\agg_chunk_33.parquet\n",
      "Processing chunk 35/200\n",
      "Saved data\\train_data\\agg_chunk_34.parquet\n",
      "Processing chunk 36/200\n",
      "Saved data\\train_data\\agg_chunk_35.parquet\n",
      "Processing chunk 37/200\n",
      "Saved data\\train_data\\agg_chunk_36.parquet\n",
      "Processing chunk 38/200\n",
      "Saved data\\train_data\\agg_chunk_37.parquet\n",
      "Processing chunk 39/200\n",
      "Saved data\\train_data\\agg_chunk_38.parquet\n",
      "Processing chunk 40/200\n",
      "Saved data\\train_data\\agg_chunk_39.parquet\n",
      "Processing chunk 41/200\n",
      "Saved data\\train_data\\agg_chunk_40.parquet\n",
      "Processing chunk 42/200\n",
      "Saved data\\train_data\\agg_chunk_41.parquet\n",
      "Processing chunk 43/200\n",
      "Saved data\\train_data\\agg_chunk_42.parquet\n",
      "Processing chunk 44/200\n",
      "Saved data\\train_data\\agg_chunk_43.parquet\n",
      "Processing chunk 45/200\n",
      "Saved data\\train_data\\agg_chunk_44.parquet\n",
      "Processing chunk 46/200\n",
      "Saved data\\train_data\\agg_chunk_45.parquet\n",
      "Processing chunk 47/200\n",
      "Saved data\\train_data\\agg_chunk_46.parquet\n",
      "Processing chunk 48/200\n",
      "Saved data\\train_data\\agg_chunk_47.parquet\n",
      "Processing chunk 49/200\n",
      "Saved data\\train_data\\agg_chunk_48.parquet\n",
      "Processing chunk 50/200\n",
      "Saved data\\train_data\\agg_chunk_49.parquet\n",
      "Processing chunk 51/200\n",
      "Saved data\\train_data\\agg_chunk_50.parquet\n",
      "Processing chunk 52/200\n",
      "Saved data\\train_data\\agg_chunk_51.parquet\n",
      "Processing chunk 53/200\n",
      "Saved data\\train_data\\agg_chunk_52.parquet\n",
      "Processing chunk 54/200\n",
      "Saved data\\train_data\\agg_chunk_53.parquet\n",
      "Processing chunk 55/200\n",
      "Saved data\\train_data\\agg_chunk_54.parquet\n",
      "Processing chunk 56/200\n",
      "Saved data\\train_data\\agg_chunk_55.parquet\n",
      "Processing chunk 57/200\n",
      "Saved data\\train_data\\agg_chunk_56.parquet\n",
      "Processing chunk 58/200\n",
      "Saved data\\train_data\\agg_chunk_57.parquet\n",
      "Processing chunk 59/200\n",
      "Saved data\\train_data\\agg_chunk_58.parquet\n",
      "Processing chunk 60/200\n",
      "Saved data\\train_data\\agg_chunk_59.parquet\n",
      "Processing chunk 61/200\n",
      "Saved data\\train_data\\agg_chunk_60.parquet\n",
      "Processing chunk 62/200\n",
      "Saved data\\train_data\\agg_chunk_61.parquet\n",
      "Processing chunk 63/200\n",
      "Saved data\\train_data\\agg_chunk_62.parquet\n",
      "Processing chunk 64/200\n",
      "Saved data\\train_data\\agg_chunk_63.parquet\n",
      "Processing chunk 65/200\n",
      "Saved data\\train_data\\agg_chunk_64.parquet\n",
      "Processing chunk 66/200\n",
      "Saved data\\train_data\\agg_chunk_65.parquet\n",
      "Processing chunk 67/200\n",
      "Saved data\\train_data\\agg_chunk_66.parquet\n",
      "Processing chunk 68/200\n",
      "Saved data\\train_data\\agg_chunk_67.parquet\n",
      "Processing chunk 69/200\n",
      "Saved data\\train_data\\agg_chunk_68.parquet\n",
      "Processing chunk 70/200\n",
      "Saved data\\train_data\\agg_chunk_69.parquet\n",
      "Processing chunk 71/200\n",
      "Saved data\\train_data\\agg_chunk_70.parquet\n",
      "Processing chunk 72/200\n",
      "Saved data\\train_data\\agg_chunk_71.parquet\n",
      "Processing chunk 73/200\n",
      "Saved data\\train_data\\agg_chunk_72.parquet\n",
      "Processing chunk 74/200\n",
      "Saved data\\train_data\\agg_chunk_73.parquet\n",
      "Processing chunk 75/200\n",
      "Saved data\\train_data\\agg_chunk_74.parquet\n",
      "Processing chunk 76/200\n",
      "Saved data\\train_data\\agg_chunk_75.parquet\n",
      "Processing chunk 77/200\n",
      "Saved data\\train_data\\agg_chunk_76.parquet\n",
      "Processing chunk 78/200\n",
      "Saved data\\train_data\\agg_chunk_77.parquet\n",
      "Processing chunk 79/200\n",
      "Saved data\\train_data\\agg_chunk_78.parquet\n",
      "Processing chunk 80/200\n",
      "Saved data\\train_data\\agg_chunk_79.parquet\n",
      "Processing chunk 81/200\n",
      "Saved data\\train_data\\agg_chunk_80.parquet\n",
      "Processing chunk 82/200\n",
      "Saved data\\train_data\\agg_chunk_81.parquet\n",
      "Processing chunk 83/200\n",
      "Saved data\\train_data\\agg_chunk_82.parquet\n",
      "Processing chunk 84/200\n",
      "Saved data\\train_data\\agg_chunk_83.parquet\n",
      "Processing chunk 85/200\n",
      "Saved data\\train_data\\agg_chunk_84.parquet\n",
      "Processing chunk 86/200\n",
      "Saved data\\train_data\\agg_chunk_85.parquet\n",
      "Processing chunk 87/200\n",
      "Saved data\\train_data\\agg_chunk_86.parquet\n",
      "Processing chunk 88/200\n",
      "Saved data\\train_data\\agg_chunk_87.parquet\n",
      "Processing chunk 89/200\n",
      "Saved data\\train_data\\agg_chunk_88.parquet\n",
      "Processing chunk 90/200\n",
      "Saved data\\train_data\\agg_chunk_89.parquet\n",
      "Processing chunk 91/200\n",
      "Saved data\\train_data\\agg_chunk_90.parquet\n",
      "Processing chunk 92/200\n",
      "Saved data\\train_data\\agg_chunk_91.parquet\n",
      "Processing chunk 93/200\n",
      "Saved data\\train_data\\agg_chunk_92.parquet\n",
      "Processing chunk 94/200\n",
      "Saved data\\train_data\\agg_chunk_93.parquet\n",
      "Processing chunk 95/200\n",
      "Saved data\\train_data\\agg_chunk_94.parquet\n",
      "Processing chunk 96/200\n",
      "Saved data\\train_data\\agg_chunk_95.parquet\n",
      "Processing chunk 97/200\n",
      "Saved data\\train_data\\agg_chunk_96.parquet\n",
      "Processing chunk 98/200\n",
      "Saved data\\train_data\\agg_chunk_97.parquet\n",
      "Processing chunk 99/200\n",
      "Saved data\\train_data\\agg_chunk_98.parquet\n",
      "Processing chunk 100/200\n",
      "Saved data\\train_data\\agg_chunk_99.parquet\n",
      "Processing chunk 101/200\n",
      "Saved data\\train_data\\agg_chunk_100.parquet\n",
      "Processing chunk 102/200\n",
      "Saved data\\train_data\\agg_chunk_101.parquet\n",
      "Processing chunk 103/200\n",
      "Saved data\\train_data\\agg_chunk_102.parquet\n",
      "Processing chunk 104/200\n",
      "Saved data\\train_data\\agg_chunk_103.parquet\n",
      "Processing chunk 105/200\n",
      "Saved data\\train_data\\agg_chunk_104.parquet\n",
      "Processing chunk 106/200\n",
      "Saved data\\train_data\\agg_chunk_105.parquet\n",
      "Processing chunk 107/200\n",
      "Saved data\\train_data\\agg_chunk_106.parquet\n",
      "Processing chunk 108/200\n",
      "Saved data\\train_data\\agg_chunk_107.parquet\n",
      "Processing chunk 109/200\n",
      "Saved data\\train_data\\agg_chunk_108.parquet\n",
      "Processing chunk 110/200\n",
      "Saved data\\train_data\\agg_chunk_109.parquet\n",
      "Processing chunk 111/200\n",
      "Saved data\\train_data\\agg_chunk_110.parquet\n",
      "Processing chunk 112/200\n",
      "Saved data\\train_data\\agg_chunk_111.parquet\n",
      "Processing chunk 113/200\n",
      "Saved data\\train_data\\agg_chunk_112.parquet\n",
      "Processing chunk 114/200\n",
      "Saved data\\train_data\\agg_chunk_113.parquet\n",
      "Processing chunk 115/200\n",
      "Saved data\\train_data\\agg_chunk_114.parquet\n",
      "Processing chunk 116/200\n",
      "Saved data\\train_data\\agg_chunk_115.parquet\n",
      "Processing chunk 117/200\n",
      "Saved data\\train_data\\agg_chunk_116.parquet\n",
      "Processing chunk 118/200\n",
      "Saved data\\train_data\\agg_chunk_117.parquet\n",
      "Processing chunk 119/200\n",
      "Saved data\\train_data\\agg_chunk_118.parquet\n",
      "Processing chunk 120/200\n",
      "Saved data\\train_data\\agg_chunk_119.parquet\n",
      "Processing chunk 121/200\n",
      "Saved data\\train_data\\agg_chunk_120.parquet\n",
      "Processing chunk 122/200\n",
      "Saved data\\train_data\\agg_chunk_121.parquet\n",
      "Processing chunk 123/200\n",
      "Saved data\\train_data\\agg_chunk_122.parquet\n",
      "Processing chunk 124/200\n",
      "Saved data\\train_data\\agg_chunk_123.parquet\n",
      "Processing chunk 125/200\n",
      "Saved data\\train_data\\agg_chunk_124.parquet\n",
      "Processing chunk 126/200\n",
      "Saved data\\train_data\\agg_chunk_125.parquet\n",
      "Processing chunk 127/200\n",
      "Saved data\\train_data\\agg_chunk_126.parquet\n",
      "Processing chunk 128/200\n",
      "Saved data\\train_data\\agg_chunk_127.parquet\n",
      "Processing chunk 129/200\n",
      "Saved data\\train_data\\agg_chunk_128.parquet\n",
      "Processing chunk 130/200\n",
      "Saved data\\train_data\\agg_chunk_129.parquet\n",
      "Processing chunk 131/200\n",
      "Saved data\\train_data\\agg_chunk_130.parquet\n",
      "Processing chunk 132/200\n",
      "Saved data\\train_data\\agg_chunk_131.parquet\n",
      "Processing chunk 133/200\n",
      "Saved data\\train_data\\agg_chunk_132.parquet\n",
      "Processing chunk 134/200\n",
      "Saved data\\train_data\\agg_chunk_133.parquet\n",
      "Processing chunk 135/200\n",
      "Saved data\\train_data\\agg_chunk_134.parquet\n",
      "Processing chunk 136/200\n",
      "Saved data\\train_data\\agg_chunk_135.parquet\n",
      "Processing chunk 137/200\n",
      "Saved data\\train_data\\agg_chunk_136.parquet\n",
      "Processing chunk 138/200\n",
      "Saved data\\train_data\\agg_chunk_137.parquet\n",
      "Processing chunk 139/200\n",
      "Saved data\\train_data\\agg_chunk_138.parquet\n",
      "Processing chunk 140/200\n",
      "Saved data\\train_data\\agg_chunk_139.parquet\n",
      "Processing chunk 141/200\n",
      "Saved data\\train_data\\agg_chunk_140.parquet\n",
      "Processing chunk 142/200\n",
      "Saved data\\train_data\\agg_chunk_141.parquet\n",
      "Processing chunk 143/200\n",
      "Saved data\\train_data\\agg_chunk_142.parquet\n",
      "Processing chunk 144/200\n",
      "Saved data\\train_data\\agg_chunk_143.parquet\n",
      "Processing chunk 145/200\n",
      "Saved data\\train_data\\agg_chunk_144.parquet\n",
      "Processing chunk 146/200\n",
      "Saved data\\train_data\\agg_chunk_145.parquet\n",
      "Processing chunk 147/200\n",
      "Saved data\\train_data\\agg_chunk_146.parquet\n",
      "Processing chunk 148/200\n",
      "Saved data\\train_data\\agg_chunk_147.parquet\n",
      "Processing chunk 149/200\n",
      "Saved data\\train_data\\agg_chunk_148.parquet\n",
      "Processing chunk 150/200\n",
      "Saved data\\train_data\\agg_chunk_149.parquet\n",
      "Processing chunk 151/200\n",
      "Saved data\\train_data\\agg_chunk_150.parquet\n",
      "Processing chunk 152/200\n",
      "Saved data\\train_data\\agg_chunk_151.parquet\n",
      "Processing chunk 153/200\n",
      "Saved data\\train_data\\agg_chunk_152.parquet\n",
      "Processing chunk 154/200\n",
      "Saved data\\train_data\\agg_chunk_153.parquet\n",
      "Processing chunk 155/200\n",
      "Saved data\\train_data\\agg_chunk_154.parquet\n",
      "Processing chunk 156/200\n",
      "Saved data\\train_data\\agg_chunk_155.parquet\n",
      "Processing chunk 157/200\n",
      "Saved data\\train_data\\agg_chunk_156.parquet\n",
      "Processing chunk 158/200\n",
      "Saved data\\train_data\\agg_chunk_157.parquet\n",
      "Processing chunk 159/200\n",
      "Saved data\\train_data\\agg_chunk_158.parquet\n",
      "Processing chunk 160/200\n",
      "Saved data\\train_data\\agg_chunk_159.parquet\n",
      "Processing chunk 161/200\n",
      "Saved data\\train_data\\agg_chunk_160.parquet\n",
      "Processing chunk 162/200\n",
      "Saved data\\train_data\\agg_chunk_161.parquet\n",
      "Processing chunk 163/200\n",
      "Saved data\\train_data\\agg_chunk_162.parquet\n",
      "Processing chunk 164/200\n",
      "Saved data\\train_data\\agg_chunk_163.parquet\n",
      "Processing chunk 165/200\n",
      "Saved data\\train_data\\agg_chunk_164.parquet\n",
      "Processing chunk 166/200\n",
      "Saved data\\train_data\\agg_chunk_165.parquet\n",
      "Processing chunk 167/200\n",
      "Saved data\\train_data\\agg_chunk_166.parquet\n",
      "Processing chunk 168/200\n",
      "Saved data\\train_data\\agg_chunk_167.parquet\n",
      "Processing chunk 169/200\n",
      "Saved data\\train_data\\agg_chunk_168.parquet\n",
      "Processing chunk 170/200\n",
      "Saved data\\train_data\\agg_chunk_169.parquet\n",
      "Processing chunk 171/200\n",
      "Saved data\\train_data\\agg_chunk_170.parquet\n",
      "Processing chunk 172/200\n",
      "Saved data\\train_data\\agg_chunk_171.parquet\n",
      "Processing chunk 173/200\n",
      "Saved data\\train_data\\agg_chunk_172.parquet\n",
      "Processing chunk 174/200\n",
      "Saved data\\train_data\\agg_chunk_173.parquet\n",
      "Processing chunk 175/200\n",
      "Saved data\\train_data\\agg_chunk_174.parquet\n",
      "Processing chunk 176/200\n",
      "Saved data\\train_data\\agg_chunk_175.parquet\n",
      "Processing chunk 177/200\n",
      "Saved data\\train_data\\agg_chunk_176.parquet\n",
      "Processing chunk 178/200\n",
      "Saved data\\train_data\\agg_chunk_177.parquet\n",
      "Processing chunk 179/200\n",
      "Saved data\\train_data\\agg_chunk_178.parquet\n",
      "Processing chunk 180/200\n",
      "Saved data\\train_data\\agg_chunk_179.parquet\n",
      "Processing chunk 181/200\n",
      "Saved data\\train_data\\agg_chunk_180.parquet\n",
      "Processing chunk 182/200\n",
      "Saved data\\train_data\\agg_chunk_181.parquet\n",
      "Processing chunk 183/200\n",
      "Saved data\\train_data\\agg_chunk_182.parquet\n",
      "Processing chunk 184/200\n",
      "Saved data\\train_data\\agg_chunk_183.parquet\n",
      "Processing chunk 185/200\n",
      "Saved data\\train_data\\agg_chunk_184.parquet\n",
      "Processing chunk 186/200\n",
      "Saved data\\train_data\\agg_chunk_185.parquet\n",
      "Processing chunk 187/200\n",
      "Saved data\\train_data\\agg_chunk_186.parquet\n",
      "Processing chunk 188/200\n",
      "Saved data\\train_data\\agg_chunk_187.parquet\n",
      "Processing chunk 189/200\n",
      "Saved data\\train_data\\agg_chunk_188.parquet\n",
      "Processing chunk 190/200\n",
      "Saved data\\train_data\\agg_chunk_189.parquet\n",
      "Processing chunk 191/200\n",
      "Saved data\\train_data\\agg_chunk_190.parquet\n",
      "Processing chunk 192/200\n",
      "Saved data\\train_data\\agg_chunk_191.parquet\n",
      "Processing chunk 193/200\n",
      "Saved data\\train_data\\agg_chunk_192.parquet\n",
      "Processing chunk 194/200\n",
      "Saved data\\train_data\\agg_chunk_193.parquet\n",
      "Processing chunk 195/200\n",
      "Saved data\\train_data\\agg_chunk_194.parquet\n",
      "Processing chunk 196/200\n",
      "Saved data\\train_data\\agg_chunk_195.parquet\n",
      "Processing chunk 197/200\n",
      "Saved data\\train_data\\agg_chunk_196.parquet\n",
      "Processing chunk 198/200\n",
      "Saved data\\train_data\\agg_chunk_197.parquet\n",
      "Processing chunk 199/200\n",
      "Saved data\\train_data\\agg_chunk_198.parquet\n",
      "Processing chunk 200/200\n",
      "Saved data\\train_data\\agg_chunk_199.parquet\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
      "\u001b[1;31mПроверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
      "\u001b[1;31mЩелкните <a href='https://aka.ms/vscodeJupyterKernelCrash'>здесь</a>, чтобы получить дополнительные сведения. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "\n",
    "# Пути\n",
    "orders_path = \"./data/ml_ozon_recsys_train_final_apparel_orders_data/*.parquet\"\n",
    "tracker_path = \"./data/ml_ozon_recsys_train_final_apparel_tracker_data/*.parquet\"\n",
    "output_dir = Path(\"./data/train_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "df_orders = (pl.scan_parquet(orders_path)\n",
    "             .select([\"user_id\", \"item_id\", \"last_status\"])\n",
    "             .with_columns([\n",
    "                   pl.col(\"user_id\").cast(pl.Int64),\n",
    "                    pl.col(\"item_id\").cast(pl.Int64),\n",
    "                    pl.col(\"last_status\")\n",
    "             ])\n",
    "             .filter(pl.col(\"last_status\") != \"proccesed_orders\"))\n",
    "\n",
    "\n",
    "tracker_files = sorted(glob.glob(tracker_path))\n",
    "chunk_size = 1  \n",
    "\n",
    "def encode_actions(df):\n",
    "    return df.with_columns([\n",
    "        (pl.col(\"action_type\") == \"view_description\").cast(pl.Int32).alias(\"action_type_view_description\"),\n",
    "        (pl.col(\"action_type\") == \"to_cart\").cast(pl.Int32).alias(\"action_type_to_cart\"),\n",
    "        (pl.col(\"action_type\") == \"page_view\").cast(pl.Int32).alias(\"action_type_page_view\"),\n",
    "        (pl.col(\"action_type\") == \"favorite\").cast(pl.Int32).alias(\"action_type_favorite\"),\n",
    "        (pl.col(\"action_type\") == \"unfavorite\").cast(pl.Int32).alias(\"action_type_unfavorite\"),\n",
    "        (pl.col(\"action_type\") == \"review_view\").cast(pl.Int32).alias(\"action_type_review_view\"),\n",
    "        (pl.col(\"action_type\") == \"remove\").cast(pl.Int32).alias(\"action_type_remove\"),\n",
    "        pl.when(pl.col(\"last_status\") == \"canceled_orders\").then(0)\n",
    "          .when(pl.col(\"last_status\") == \"delivered_orders\").then(1)\n",
    "          .otherwise(0)\n",
    "          .cast(pl.Int8)\n",
    "          .alias(\"last_status\")\n",
    "    ]).drop(\"action_type\")\n",
    "\n",
    "for i in range(0, len(tracker_files), chunk_size):\n",
    "    files_chunk = tracker_files[i:i+chunk_size]\n",
    "    print(f\"Processing chunk {i//chunk_size + 1}/{(len(tracker_files)+chunk_size-1)//chunk_size}\")\n",
    "\n",
    "    chunk_df = (pl.scan_parquet(files_chunk)\n",
    "                .with_columns([\n",
    "                    pl.col(\"user_id\").cast(pl.Int64),\n",
    "                    pl.col(\"item_id\").cast(pl.Int64),\n",
    "                ]))\n",
    "\n",
    "    temp = (\n",
    "        chunk_df\n",
    "        .join(df_orders, on=[\"item_id\",\"user_id\"], how=\"left\")\n",
    "    )\n",
    "    temp = encode_actions(temp)\n",
    "\n",
    "    temp_agg = temp.group_by([\"user_id\",\"item_id\"]).agg([\n",
    "        pl.col([\n",
    "            \"action_type_view_description\",\n",
    "            \"action_type_to_cart\",\n",
    "            \"action_type_page_view\",\n",
    "            \"action_type_favorite\",\n",
    "            \"action_type_unfavorite\",\n",
    "            \"action_type_review_view\",\n",
    "            \"action_type_remove\"\n",
    "        ]).sum(),\n",
    "        pl.col(\"last_status\").first()\n",
    "    ])\n",
    "\n",
    "    output_file = output_dir / f\"agg_chunk_{i//chunk_size}.parquet\"\n",
    "    temp_agg.collect(streaming=True).write_parquet(output_file)\n",
    "    print(f\"Saved {output_file}\")\n",
    "\n",
    "\n",
    "all_chunks = pl.scan_parquet(str(output_dir / \"*.parquet\"))\n",
    "\n",
    "final_result = (\n",
    "    all_chunks\n",
    "    .group_by([\"user_id\",\"item_id\"])\n",
    "    .agg([\n",
    "        pl.col([\n",
    "            \"action_type_view_description\",\n",
    "            \"action_type_to_cart\",\n",
    "            \"action_type_page_view\",\n",
    "            \"action_type_favorite\",\n",
    "            \"action_type_unfavorite\",\n",
    "            \"action_type_review_view\",\n",
    "            \"action_type_remove\"\n",
    "        ]).sum(),\n",
    "        pl.col(\"last_status\").first()\n",
    "    ])\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb56915",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_dir = Path(\"./data/train_data\")\n",
    "output_dir = Path(\"./data/train_matrix_dir\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "all_files = sorted(glob.glob(str(chunks_dir / \"*.parquet\")))\n",
    "\n",
    "all_data = pl.scan_parquet(all_files)\n",
    "\n",
    "agg_data = (\n",
    "    all_data\n",
    "    .group_by([\"user_id\",\"item_id\"])\n",
    "    .agg([\n",
    "        pl.col([\n",
    "            \"action_type_view_description\",\n",
    "            \"action_type_to_cart\",\n",
    "            \"action_type_page_view\",\n",
    "            \"action_type_favorite\",\n",
    "            \"action_type_unfavorite\",\n",
    "            \"action_type_review_view\",\n",
    "            \"action_type_remove\"\n",
    "        ]).sum(),\n",
    "        pl.col(\"last_status\").first()\n",
    "    ])\n",
    ")\n",
    "\n",
    "df_collected = agg_data.collect(streaming=True)\n",
    "\n",
    "n_files = 20\n",
    "rows_per_file = math.ceil(df_collected.height / n_files)\n",
    "\n",
    "for i in range(n_files):\n",
    "    start = i * rows_per_file\n",
    "    end = min((i+1) * rows_per_file, df_collected.height)\n",
    "    df_chunk = df_collected[start:end]\n",
    "    df_chunk.write_parquet(output_dir / f\"agg_10_{i+1}.parquet\")\n",
    "    print(f\"Saved file {i+1} with rows {start}-{end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffeb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [15:27<00:00, 185.53s/it]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mПри выполнении кода в текущей ячейке или предыдущей ячейке ядро аварийно завершило работу. \n",
      "\u001b[1;31mПроверьте код в ячейках, чтобы определить возможную причину сбоя. \n",
      "\u001b[1;31mЩелкните <a href='https://aka.ms/vscodeJupyterKernelCrash'>здесь</a>, чтобы получить дополнительные сведения. \n",
      "\u001b[1;31mПодробнее см. в <a href='command:jupyter.viewOutput'>журнале Jupyter</a>."
     ]
    }
   ],
   "source": [
    "# Группировка паркетов в более сжатом виде \n",
    "\n",
    "\n",
    "\n",
    "chunks_dir = Path(\"./data/grouped3\")\n",
    "\n",
    "all_files = sorted(glob.glob(str(chunks_dir / \"*.parquet\")))\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "out_path = Path(\"./data/grouped4\")\n",
    "out_path.mkdir(exist_ok=True)\n",
    "n = 2\n",
    "\n",
    "for i in tqdm(range(0, len(all_files), n)):\n",
    "    batch = all_files[i:i+n]\n",
    "    \n",
    "    # читаем сразу все parquet из батча\n",
    "    df = pl.scan_parquet(batch)\n",
    "    agg_data = (\n",
    "    df\n",
    "    .group_by([\"user_id\",\"item_id\"])\n",
    "    .agg([\n",
    "        pl.col([\n",
    "            \"action_type_view_description\",\n",
    "            \"action_type_to_cart\",\n",
    "            \"action_type_page_view\",\n",
    "            \"action_type_favorite\",\n",
    "            \"action_type_unfavorite\",\n",
    "            \"action_type_review_view\",\n",
    "            \"action_type_remove\"\n",
    "        ]).sum(),\n",
    "        pl.col(\"last_status\").first()\n",
    "    ])\n",
    "    )\n",
    "    del df\n",
    "    out_file = out_path / f\"grouped_batch_{i//n + 1}.parquet\"\n",
    "    agg_data.sink_parquet(out_file)\n",
    "    del agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d8fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"page_view\" \"to_cart\" \"review_view\" \"unfavorite\" \"remove\"    \"favorite\" \"view_description\"\n",
    "#     1           10         5           -10           -5          8              3\n",
    "#   0.361511  2.101614  0.022923       0.077276    -1.448458     -0.024284      -0.004144\n",
    "\n",
    "actions_coefs = np.array([0.361511, 2.101614, 0.022923, 0.077276, -1.448458, -0.024284, -0.004144])\n",
    "cols = [\"action_type_page_view\", \"action_type_to_cart\", \"action_type_review_view\", \"action_type_unfavorite\", \"action_type_remove\", \"action_type_favorite\", \"action_type_view_description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a90474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2c9d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_matrix_R(train_data_path, output_path, actions_coefs, columns, n_parquets = 10):\n",
    "    all_files = sorted(glob.glob(str(train_data_path /\"*.parquet\")))\n",
    "    print(all_files)\n",
    "    out_dir = Path(output_path)\n",
    "    out_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    r = sum(pl.col(col)*coef for coef, col in zip(actions_coefs, columns))\n",
    "    iter = 0\n",
    "    for file in tqdm(all_files):\n",
    "        iter += 1\n",
    "        data = pl.scan_parquet(file).with_columns([\n",
    "            r.cast(pl.Float32).alias(\"rating\")\n",
    "        ]).drop(columns).drop(\"last_status\")\n",
    "    \n",
    "        data.sink_parquet(out_dir / f\"{iter}.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "143b55ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data\\\\grouped4\\\\grouped_batch_1.parquet', 'data\\\\grouped4\\\\grouped_batch_2.parquet', 'data\\\\grouped4\\\\grouped_batch_3.parquet', 'data\\\\grouped4\\\\grouped_batch_4.parquet', 'data\\\\grouped4\\\\grouped_batch_5.parquet']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:09<00:00, 13.81s/it]\n"
     ]
    }
   ],
   "source": [
    "gen_matrix_R(Path(\".\\data\\grouped4\"), Path(\".\\data\\matrix_R_coord\"),actions_coefs, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2b127",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
